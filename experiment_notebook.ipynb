{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install pytorch-lightning-bolts;\n",
    "!pip install gdown;\n",
    "!pip install openpyxl;"
   ],
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2022-07-31T09:28:34.957142Z",
     "iopub.execute_input": "2022-07-31T09:28:34.957994Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Download spectogram dataset from google drive\n",
    "!gdown 1Wj7Hl5d94iWFzmnoMdofnWq6XQJvTZor"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:30.204671Z",
     "iopub.execute_input": "2022-07-29T19:42:30.205292Z",
     "iopub.status.idle": "2022-07-29T19:42:34.750450Z",
     "shell.execute_reply.started": "2022-07-29T19:42:30.205247Z",
     "shell.execute_reply": "2022-07-29T19:42:34.749394Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip -q spectogram_dataset.zip"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import gdown\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.optim import Adam\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from pl_bolts.models.autoencoders.components import (\n",
    "    resnet18_decoder,\n",
    "    resnet18_encoder,\n",
    ")\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "pl.seed_everything(1234)"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:38.194683Z",
     "iopub.execute_input": "2022-07-29T19:42:38.194983Z",
     "iopub.status.idle": "2022-07-29T19:42:43.056404Z",
     "shell.execute_reply.started": "2022-07-29T19:42:38.194955Z",
     "shell.execute_reply": "2022-07-29T19:42:43.055493Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SpectogramDataset(Dataset):\n",
    "    '''\n",
    "    A Pytorch dataset that loads all spectograms from the directory passed in path_to_images.\n",
    "    Or if images_names!=None, loads only spectograms that are listed in images_names.\n",
    "    '''\n",
    "    def __init__(self,path_to_images,images_names = None,transforms_func = None):\n",
    "\n",
    "\n",
    "        self.path_to_images = path_to_images\n",
    "        self.images_names = images_names if images_names else os.listdir(path_to_images)\n",
    "        self.transforms = transforms_func\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        full_path_to_image = os.path.join(self.path_to_images,self.images_names[idx])\n",
    "        # Read a grayscale image\n",
    "        image = Image.open(full_path_to_image).convert('L')\n",
    "        \n",
    "        if self.transforms!=None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return  image"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.057924Z",
     "iopub.execute_input": "2022-07-29T19:42:43.058639Z",
     "iopub.status.idle": "2022-07-29T19:42:43.065990Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.058599Z",
     "shell.execute_reply": "2022-07-29T19:42:43.065078Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "base_path = './spectogram_dataset'\n",
    "train_path = os.path.join(base_path,'train')\n",
    "valid_path = os.path.join(base_path,'valid')\n",
    "test_path = os.path.join(base_path,'test')\n",
    "\n",
    "base_image_transforms = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((216,216))\n",
    "]\n",
    "\n",
    "train_ds = SpectogramDataset(train_path, transforms_func = transforms.Compose(base_image_transforms))\n",
    "valid_ds = SpectogramDataset(valid_path, transforms_func = transforms.Compose(base_image_transforms))\n",
    "test_ds = SpectogramDataset(test_path,   transforms_func = transforms.Compose(base_image_transforms))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.067445Z",
     "iopub.execute_input": "2022-07-29T19:42:43.068183Z",
     "iopub.status.idle": "2022-07-29T19:42:43.081874Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.068147Z",
     "shell.execute_reply": "2022-07-29T19:42:43.080865Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Train len: {len(train_ds)}')\n",
    "print(f'Valid len: {len(valid_ds)}')\n",
    "print(f'Test len: {len(test_ds)}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.083281Z",
     "iopub.execute_input": "2022-07-29T19:42:43.084920Z",
     "iopub.status.idle": "2022-07-29T19:42:43.094475Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.084881Z",
     "shell.execute_reply": "2022-07-29T19:42:43.093239Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class VAE(pl.LightningModule):\n",
    "    def __init__(self, enc_out_dim=512, latent_dim=128, input_height=28, in_channels=1, lr=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.lr = lr\n",
    "        # encoder, decoder\n",
    "        self.encoder = resnet18_encoder(False, False)\n",
    "        self.decoder = resnet18_decoder(\n",
    "            latent_dim=latent_dim,\n",
    "            input_height=input_height,\n",
    "            first_conv=False,\n",
    "            maxpool1=False\n",
    "        )\n",
    "        # Edit the first Conv layer to adjust the model for images with different\n",
    "        # number of channels\n",
    "        self.encoder.conv1 = nn.Conv2d(in_channels, out_channels=64, \n",
    "                               kernel_size = (3,3), stride=(1,1), \n",
    "                               padding=(1,1), bias=False)\n",
    "        self.decoder.conv1 = nn.Conv2d(in_channels=64, out_channels=in_channels, \n",
    "                               kernel_size = (3,3), stride=(1,1), \n",
    "                               padding=(1,1), bias=False)\n",
    "\n",
    "        # distribution parameters\n",
    "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
    "\n",
    "        # for the gaussian likelihood\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "        scale = torch.exp(logscale)\n",
    "        mean = x_hat\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "\n",
    "        # measure prob of seeing image under p(x|z)\n",
    "        log_pxz = dist.log_prob(x)\n",
    "        return log_pxz.sum(dim=(1, 2, 3))\n",
    "\n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "    \n",
    "    def encode(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            x_encoded = self.encoder(x)\n",
    "            mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "            std = torch.exp(log_var / 2)\n",
    "            z = self.sample_z_from_q(mu,std)\n",
    "        return z\n",
    "            \n",
    "        \n",
    "    def sample_z_from_q(self,mu,std):\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch\n",
    "\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        z = self.sample_z_from_q(mu,std)\n",
    "\n",
    "        # decoded\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "\n",
    "        # kl\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        self.log_dict({\n",
    "            'elbo_train': elbo,\n",
    "            'kl_train': kl.mean(),\n",
    "            'recon_loss_train': recon_loss.mean(),\n",
    "        },\n",
    "            on_step=False, on_epoch=True)\n",
    "\n",
    "        return elbo\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch\n",
    "\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "        z = q.rsample()\n",
    "\n",
    "        # decoded\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "\n",
    "        # kl\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        self.log_dict({\n",
    "            'elbo_valid': elbo,\n",
    "            'kl_valid': kl.mean(),\n",
    "            'recon_loss_valid': recon_loss.mean(),\n",
    "        },\n",
    "            on_step=False, on_epoch=True)\n",
    "\n",
    "        return x_hat,elbo"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.095819Z",
     "iopub.execute_input": "2022-07-29T19:42:43.096083Z",
     "iopub.status.idle": "2022-07-29T19:42:43.122581Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.096049Z",
     "shell.execute_reply": "2022-07-29T19:42:43.121573Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "LR = 1e-3\n",
    "EPOCHS = 100\n",
    "BS = 16\n",
    "num_workers = 2\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {device}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.124130Z",
     "iopub.execute_input": "2022-07-29T19:42:43.124582Z",
     "iopub.status.idle": "2022-07-29T19:42:43.194743Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.124547Z",
     "shell.execute_reply": "2022-07-29T19:42:43.193807Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(\n",
    "train_ds, batch_size=BS, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "valid_ds, batch_size=BS, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "test_ds, batch_size=BS, shuffle=False, num_workers=num_workers)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.198270Z",
     "iopub.execute_input": "2022-07-29T19:42:43.198642Z",
     "iopub.status.idle": "2022-07-29T19:42:43.205103Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.198604Z",
     "shell.execute_reply": "2022-07-29T19:42:43.203783Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "train_set =   torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,)),\n",
    "                               torchvision.transforms.Resize((24,24))]))\n",
    "\n",
    "test_set =  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,)),\n",
    "                               torchvision.transforms.Resize((24,24))\n",
    "                             ]))\n",
    "\n",
    "# Random split\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "train_set, valid_set = random_split(train_set, [train_set_size, valid_set_size])\n",
    "\n",
    "print(f'Train set: {len(train_set)}')\n",
    "print(f'Valid set: {len(valid_set)}')\n",
    "print(f'Test set: {len(test_set)}')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "train_set, batch_size=BS, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "valid_set,batch_size=BS, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    " test_set,batch_size=BS, shuffle=False)\n",
    " '''"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.206866Z",
     "iopub.execute_input": "2022-07-29T19:42:43.207257Z",
     "iopub.status.idle": "2022-07-29T19:42:43.219216Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.207217Z",
     "shell.execute_reply": "2022-07-29T19:42:43.218291Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "logger = CSVLogger(\"logs\", name=\"my_exp_name\")\n",
    "vae = VAE(input_height=216, in_channels=1, latent_dim=128, lr=LR)\n",
    "trainer = pl.Trainer(accelerator='gpu' if device=='cuda' else device,max_epochs=EPOCHS, logger=logger)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.220652Z",
     "iopub.execute_input": "2022-07-29T19:42:43.221371Z",
     "iopub.status.idle": "2022-07-29T19:42:43.442575Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.221334Z",
     "shell.execute_reply": "2022-07-29T19:42:43.441667Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.fit(vae, train_loader,valid_loader)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T19:42:43.444159Z",
     "iopub.execute_input": "2022-07-29T19:42:43.444505Z",
     "iopub.status.idle": "2022-07-29T22:40:01.627356Z",
     "shell.execute_reply.started": "2022-07-29T19:42:43.444468Z",
     "shell.execute_reply": "2022-07-29T22:40:01.626045Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Metrics"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def merge_logs(logs):\n",
    "    merged_dict = []\n",
    "    for i in range(0,len(logs),2):\n",
    "        row = {'elbo_valid':logs.iloc[i]['elbo_valid'],\n",
    "              'kl_valid':logs.iloc[i]['kl_valid'],\n",
    "              'recon_loss_valid':logs.iloc[i]['recon_loss_valid'],\n",
    "              'epoch':logs.iloc[i]['epoch'],\n",
    "              'step':logs.iloc[i]['step'],\n",
    "              'elbo_train':logs.iloc[i+1]['elbo_train'],\n",
    "              'kl_train':logs.iloc[i+1]['kl_train'],\n",
    "              'recon_loss_train':logs.iloc[i+1]['recon_loss_train']}\n",
    "        merged_dict.append(row)\n",
    "\n",
    "    merged_logs = pd.DataFrame(merged_dict)\n",
    "    return merged_logs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T22:40:11.055254Z",
     "iopub.execute_input": "2022-07-29T22:40:11.056083Z",
     "iopub.status.idle": "2022-07-29T22:40:11.064286Z",
     "shell.execute_reply.started": "2022-07-29T22:40:11.056042Z",
     "shell.execute_reply": "2022-07-29T22:40:11.062658Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_stats(merged_logs):\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(8,6),dpi=150)\n",
    "\n",
    "    axs[0][0].plot(merged_logs['epoch'],merged_logs['elbo_train'], 'b-',label='elbo_train')\n",
    "    axs[0][0].plot(merged_logs['epoch'],merged_logs['elbo_valid'], 'r--',label='elbo_valid')\n",
    "    axs[0][0].set_title('Elbo')\n",
    "    axs[0][0].set(xlabel='epoch', ylabel='Elbo loss')\n",
    "    axs[0][0].legend()\n",
    "    axs[0][0].label_outer()\n",
    "\n",
    "    axs[1][0].plot(merged_logs['epoch'],merged_logs['kl_train'], 'b-',label='kl_train')\n",
    "    axs[1][0].plot(merged_logs['epoch'],merged_logs['kl_valid'], 'r--',label='kl_valid')\n",
    "    axs[1][0].set_title('KL')\n",
    "    axs[1][0].set(xlabel='epoch', ylabel='KL loss')\n",
    "    axs[1][0].legend()\n",
    "    axs[1][0].label_outer()\n",
    "\n",
    "    axs[0][1].label_outer()\n",
    "\n",
    "\n",
    "    axs[1][1].plot(merged_logs['epoch'],merged_logs['recon_loss_train'], 'b-',label='recon_loss_train')\n",
    "    axs[1][1].plot(merged_logs['epoch'],merged_logs['recon_loss_valid'], 'r--',label='recon_loss_valid')\n",
    "    axs[1][1].set_title('Recon loss')\n",
    "    axs[1][1].set(xlabel='epoch', ylabel='Recon loss')\n",
    "    axs[1][1].invert_yaxis()\n",
    "    axs[1][1].legend()\n",
    "    #axs[1][1].label_outer()\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T22:40:12.304989Z",
     "iopub.execute_input": "2022-07-29T22:40:12.305553Z",
     "iopub.status.idle": "2022-07-29T22:40:12.317161Z",
     "shell.execute_reply.started": "2022-07-29T22:40:12.305495Z",
     "shell.execute_reply": "2022-07-29T22:40:12.316052Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "logs = pd.read_csv('./logs/my_exp_name/version_0/metrics.csv')\n",
    "merged_logs = merge_logs(logs)\n",
    "plot_stats(merged_logs)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T22:40:14.612415Z",
     "iopub.execute_input": "2022-07-29T22:40:14.613011Z",
     "iopub.status.idle": "2022-07-29T22:40:15.229544Z",
     "shell.execute_reply.started": "2022-07-29T22:40:14.612971Z",
     "shell.execute_reply": "2022-07-29T22:40:15.228585Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing "
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_distances(beats_names, base_path, similarity_metric ):\n",
    "    '''Calculates the distances of all the voxes in base_path to all the beats from the beats_names list,\n",
    "    and returns a list of stylers (dataframes with changed styles) which contain all the distances, and \n",
    "    the distances from the voxes from the same beat are highlighten green. '''\n",
    "    vae.eval()\n",
    "    \n",
    "    # Step 1. Encode the beats\n",
    "    beats_ds = SpectogramDataset(base_path, beats_names,transforms.Compose(base_image_transforms))\n",
    "    beats_dl = DataLoader(beats_ds, batch_size=len(beats_names), shuffle=False)\n",
    "    encoded_beats = []\n",
    "    for beats_batch in tqdm(beats_dl):\n",
    "        encoded_beats.append(vae.encode(beats_batch.to(device))) \n",
    "\n",
    "    encoded_beats = torch.cat(encoded_beats)\n",
    "    \n",
    "    # Step 2. Encode all the voxes in the base directory\n",
    "    # Take only original voxes (not augmented)\n",
    "    vox_names = [file_name for file_name in os.listdir(base_path) if (('vox'in file_name) and not \n",
    "                                                                                  ('pitch_scale' in file_name or \n",
    "                                                                                  'white_noise' in file_name or\n",
    "                                                                                  'time_stretch' in file_name))]\n",
    "    \n",
    "    voxes_ds = SpectogramDataset(base_path, vox_names,transforms.Compose(base_image_transforms))\n",
    "    voxes_dl = DataLoader(voxes_ds, batch_size=BS, shuffle=False)\n",
    "    encoded_voxes = []\n",
    "    for voxes_batch in tqdm(voxes_dl):\n",
    "        encoded_voxes.append(vae.encode(voxes_batch.to(device))) \n",
    "\n",
    "    encoded_voxes = torch.cat(encoded_voxes)\n",
    "    \n",
    "    # Step 3, 4. Calculate distances, prettify the final dataframe \n",
    "    def highlight_same_song(df, song_name):\n",
    "        if song_name in df['file_name']:\n",
    "            return ['background-color: green'] * len(df)\n",
    "        else:\n",
    "            return ['background-color: white'] * len(df)\n",
    "        \n",
    "    stylers_list = []\n",
    "    for i in range(len(encoded_beats)):\n",
    "        # Calculate similiarity between a specific beat section and all the voxes\n",
    "        distances = similarity_metric(encoded_voxes, encoded_beats[i][None,:])\n",
    "        # Combine voxes file names and their distances into one dataframe\n",
    "        distances_df = pd.DataFrame({'file_name': vox_names, 'distance':distances.cpu().numpy()}, columns = ['file_name', 'distance'])\n",
    "        distances_df.sort_values(by=['distance'], inplace=True)\n",
    "        distances_df.reset_index(inplace=True, drop=True)\n",
    "        # \n",
    "        song_name = beats_names[i].split('beat')[0][:-1]\n",
    "        highlight_current_song = partial(highlight_same_song, song_name=song_name)\n",
    "        styler = distances_df.style.apply(highlight_current_song, axis=1)\n",
    "        styler = styler.set_caption(f'Distances to {song_name}')\n",
    "    \n",
    "        stylers_list.append(styler)\n",
    "        \n",
    "    return stylers_list"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T22:45:53.505610Z",
     "iopub.execute_input": "2022-07-29T22:45:53.505974Z",
     "iopub.status.idle": "2022-07-29T22:45:53.519483Z",
     "shell.execute_reply.started": "2022-07-29T22:45:53.505943Z",
     "shell.execute_reply": "2022-07-29T22:45:53.518553Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### On Train"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cos_similiarity = nn.CosineSimilarity(eps=1e-6)\n",
    "def cos_distance(input1,input2):\n",
    "    return 1 - cos_similiarity(input1,input2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T22:41:57.613252Z",
     "iopub.execute_input": "2022-07-29T22:41:57.613622Z",
     "iopub.status.idle": "2022-07-29T22:41:57.618976Z",
     "shell.execute_reply.started": "2022-07-29T22:41:57.613589Z",
     "shell.execute_reply": "2022-07-29T22:41:57.617922Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "beats_names_from_train = ['baba_yaga_beat_section_1.png',\n",
    "                         'be_afraid_my_enemy_beat_section_3.png',\n",
    "                         'body_minor_beat_section_4.png',\n",
    "                         'dance_alone_beat_section_1.png']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T22:41:58.921949Z",
     "iopub.execute_input": "2022-07-29T22:41:58.922309Z",
     "iopub.status.idle": "2022-07-29T22:41:58.929084Z",
     "shell.execute_reply.started": "2022-07-29T22:41:58.922277Z",
     "shell.execute_reply": "2022-07-29T22:41:58.928105Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result_train = plot_distances(beats_names_from_train, train_path, cos_distance)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T22:45:56.966439Z",
     "iopub.execute_input": "2022-07-29T22:45:56.967049Z",
     "iopub.status.idle": "2022-07-29T22:45:58.877405Z",
     "shell.execute_reply.started": "2022-07-29T22:45:56.967009Z",
     "shell.execute_reply": "2022-07-29T22:45:58.876556Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for styler in result_train:\n",
    "    styler.to_excel(f'{styler.caption}.xlsx')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-29T23:04:06.390089Z",
     "iopub.execute_input": "2022-07-29T23:04:06.390470Z",
     "iopub.status.idle": "2022-07-29T23:04:06.854415Z",
     "shell.execute_reply.started": "2022-07-29T23:04:06.390435Z",
     "shell.execute_reply": "2022-07-29T23:04:06.853495Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### On Test + Valid"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Merge the content of two directories for convenient access\n",
    "def copy_dir_content(src, trg):\n",
    "    for file_name in tqdm(os.listdir(src)):\n",
    "        shutil.copy2(os.path.join(src,file_name), trg)\n",
    "        \n",
    "valid_test_path = os.path.join(base_path, 'test_valid')\n",
    "if not os.path.exists(valid_test_path):\n",
    "    os.mkdir(valid_test_path)  \n",
    "    copy_dir_content(valid_path, valid_test_path)\n",
    "    copy_dir_content(test_path, valid_test_path)\n",
    "    \n",
    "print(len(os.listdir(valid_test_path)))"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "beats_names_from_test_valid = ['body_minor_beat_section_2.png',\n",
    "                         'i_got_everything_beat_section_2.png',\n",
    "                         'tail_about_bogatir_beat_section_2.png',\n",
    "                         'Game_Over_beat_section_1.png']"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result_test_valid = plot_distances(beats_names_from_test_valid, valid_test_path, cos_distance)"
   ],
   "metadata": {
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}